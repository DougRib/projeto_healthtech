"""
ETAPA 2.3: Agrega√ß√£o e An√°lise Estat√≠stica
===========================================

Este m√≥dulo realiza agrega√ß√µes estat√≠sticas dos dados enriquecidos:

1. Agrega√ß√£o por RazaoSocial e UF
2. C√°lculo de m√©tricas:
   - Total de despesas
   - M√©dia por trimestre
   - Desvio padr√£o
   - Contagem de trimestres
3. Ordena√ß√£o por valor total
4. Gera√ß√£o do arquivo final

Decis√£o T√©cnica: Pandas GroupBy + Sort
- QuickSort (padr√£o Pandas): O(n log n)
- Eficiente para ~1.500 operadoras
- In-place quando poss√≠vel

Autor: [Seu Nome]
Data: 29/01/2025

Uso:
    python agregacao.py
"""

import pandas as pd
import numpy as np
import sys
import zipfile
from pathlib import Path
from datetime import datetime
import logging

PROJETO_RAIZ = Path(__file__).resolve().parents[1]
if str(PROJETO_RAIZ) not in sys.path:
    sys.path.insert(0, str(PROJETO_RAIZ))

from integracao_api.utils import configurar_logging, bytes_para_humano


# Configura√ß√£o de logging
logger = configurar_logging("agregacao.log")


class AgregadorDados:
    """
    Classe respons√°vel por agregar e analisar dados enriquecidos.
    
    Funcionalidades:
    - Agrega√ß√£o por RazaoSocial e UF
    - C√°lculos estat√≠sticos (soma, m√©dia, desvio, contagem)
    - Ordena√ß√£o por valor total
    - An√°lise de variabilidade
    """
    
    def __init__(self, arquivo_entrada: Path):
        """
        Inicializa o agregador.
        
        Args:
            arquivo_entrada: Path do CSV com dados enriquecidos
        """
        self.arquivo_entrada = arquivo_entrada
        self.df_enriquecido = None
        self.df_agregado = None
        
        logger.info("="*70)
        logger.info("INICIANDO ETAPA 2.3: AGREGA√á√ÉO E ESTAT√çSTICAS")
        logger.info("="*70)
    
    def carregar_dados(self) -> None:
        """Carrega dados enriquecidos."""
        print(f"üì• Carregando dados enriquecidos...")
        logger.info(f"Carregando: {self.arquivo_entrada}")
        
        try:
            self.df_enriquecido = pd.read_csv(
                self.arquivo_entrada,
                sep=';',
                encoding='utf-8',
                low_memory=False
            )
            print(f"  ‚úì {len(self.df_enriquecido):,} registros carregados")
            logger.info(f"Dados carregados: {len(self.df_enriquecido)} registros")
        
        except Exception as e:
            logger.error(f"Erro ao carregar dados: {e}")
            raise
    
    def preparar_dados(self) -> None:
        """
        Prepara dados para agrega√ß√£o.
        
        - Remove registros com valores inv√°lidos
        - Garante tipos de dados corretos
        - Trata valores nulos em campos chave
        """
        print(f"\n‚öôÔ∏è  Preparando dados para agrega√ß√£o...")
        logger.info("Iniciando prepara√ß√£o de dados")
        
        tamanho_original = len(self.df_enriquecido)
        
        # Converter ValorDespesas para num√©rico
        self.df_enriquecido['ValorDespesas'] = pd.to_numeric(
            self.df_enriquecido['ValorDespesas'],
            errors='coerce'
        )
        
        # Remover registros com valor nulo ou negativo
        self.df_enriquecido = self.df_enriquecido[
            (self.df_enriquecido['ValorDespesas'].notna()) &
            (self.df_enriquecido['ValorDespesas'] >= 0)
        ].copy()
        
        registros_removidos = tamanho_original - len(self.df_enriquecido)
        
        if registros_removidos > 0:
            print(f"  ‚ö†Ô∏è  {registros_removidos:,} registros removidos (valores inv√°lidos)")
            logger.warning(f"Registros removidos: {registros_removidos}")
        
        # Tratar UF nulo
        if 'UF' in self.df_enriquecido.columns:
            uf_nulos = self.df_enriquecido['UF'].isna().sum()
            if uf_nulos > 0:
                self.df_enriquecido['UF'] = self.df_enriquecido['UF'].fillna('N√ÉO_INFORMADO')
                print(f"  ‚ö†Ô∏è  {uf_nulos:,} UFs nulas preenchidas com 'N√ÉO_INFORMADO'")
        
        # Tratar RazaoSocial nulo
        if 'RazaoSocial' in self.df_enriquecido.columns:
            razao_nulos = self.df_enriquecido['RazaoSocial'].isna().sum()
            if razao_nulos > 0:
                self.df_enriquecido['RazaoSocial'] = self.df_enriquecido['RazaoSocial'].fillna('N√ÉO_INFORMADO')
                print(f"  ‚ö†Ô∏è  {razao_nulos:,} Raz√µes Sociais nulas preenchidas")
        
        print(f"  ‚úì Dados preparados: {len(self.df_enriquecido):,} registros v√°lidos")
        logger.info(f"Prepara√ß√£o conclu√≠da: {len(self.df_enriquecido)} registros v√°lidos")
    
    def agregar_dados(self) -> None:
        """
        Realiza agrega√ß√£o por RazaoSocial e UF.
        
        M√©tricas calculadas:
        - TotalDespesas: Soma de ValorDespesas
        - MediaDespesas: M√©dia de ValorDespesas
        - DesvioPadrao: Desvio padr√£o de ValorDespesas
        - NumeroTrimestres: Contagem de registros
        - MediaPorTrimestre: Total / N√∫mero de trimestres
        """
        print(f"\nüìä Agregando dados...")
        logger.info("Iniciando agrega√ß√£o")
        
        # Definir campos de agrupamento
        campos_agrupamento = ['RazaoSocial', 'UF']
        
        # Verificar se campos existem
        for campo in campos_agrupamento:
            if campo not in self.df_enriquecido.columns:
                raise ValueError(f"Campo {campo} n√£o encontrado nos dados!")
        
        # Agregar primeiro por trimestre para evitar vieses por quantidade de linhas
        print(f"  Agrupando por: {', '.join(campos_agrupamento)} e trimestre")
        df_trimestres = (
            self.df_enriquecido
            .groupby(['RazaoSocial', 'UF', 'Ano', 'Trimestre'])['ValorDespesas']
            .sum()
            .reset_index()
        )

        self.df_agregado = df_trimestres.groupby(campos_agrupamento).agg(
            TotalDespesas=('ValorDespesas', 'sum'),
            MediaDespesas=('ValorDespesas', 'mean'),
            DesvioPadrao=('ValorDespesas', 'std'),
            NumeroTrimestres=('ValorDespesas', 'count'),
        ).reset_index()

        # M√©dia por trimestre (equivalente √† m√©dia de trimestres agregados)
        self.df_agregado['MediaPorTrimestre'] = self.df_agregado['MediaDespesas']
        
        # Preencher desvio padr√£o nulo (quando s√≥ h√° 1 registro) com 0
        self.df_agregado['DesvioPadrao'] = self.df_agregado['DesvioPadrao'].fillna(0)
        
        # Adicionar flag de alta variabilidade
        # Consideramos alta variabilidade quando CV > 50%
        self.df_agregado['CoeficienteVariacao'] = (
            self.df_agregado['DesvioPadrao'] / self.df_agregado['MediaDespesas']
        ) * 100
        
        self.df_agregado['AltaVariabilidade'] = (
            self.df_agregado['CoeficienteVariacao'] > 50
        )
        
        print(f"  ‚úì Agrega√ß√£o conclu√≠da: {len(self.df_agregado):,} grupos")
        logger.info(f"Agrega√ß√£o conclu√≠da: {len(self.df_agregado)} grupos")
    
    def ordenar_dados(self) -> None:
        """
        Ordena dados por TotalDespesas (maior para menor).
        
        Decis√£o T√©cnica: QuickSort (padr√£o Pandas)
        - Complexidade: O(n log n)
        - Performance adequada para ~1.500 registros
        - In-place quando poss√≠vel
        """
        print(f"\nüîÉ Ordenando dados...")
        logger.info("Ordenando por TotalDespesas")
        
        self.df_agregado = self.df_agregado.sort_values(
            'TotalDespesas',
            ascending=False
        ).reset_index(drop=True)
        
        # Adicionar ranking
        self.df_agregado['Ranking'] = range(1, len(self.df_agregado) + 1)
        
        # Reordenar colunas
        colunas_ordenadas = [
            'Ranking',
            'RazaoSocial',
            'UF',
            'TotalDespesas',
            'MediaDespesas',
            'MediaPorTrimestre',
            'DesvioPadrao',
            'CoeficienteVariacao',
            'NumeroTrimestres',
            'AltaVariabilidade'
        ]
        
        self.df_agregado = self.df_agregado[colunas_ordenadas]
        
        print(f"  ‚úì Dados ordenados por TotalDespesas")
        logger.info("Ordena√ß√£o conclu√≠da")
    
    def gerar_analise_estatistica(self) -> dict:
        """
        Gera an√°lise estat√≠stica detalhada dos dados agregados.
        
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        print(f"\nüìà Gerando an√°lise estat√≠stica...")
        
        estatisticas = {
            'total_grupos': len(self.df_agregado),
            'soma_total_despesas': self.df_agregado['TotalDespesas'].sum(),
            'media_total_despesas': self.df_agregado['TotalDespesas'].mean(),
            'mediana_total_despesas': self.df_agregado['TotalDespesas'].median(),
            'min_total_despesas': self.df_agregado['TotalDespesas'].min(),
            'max_total_despesas': self.df_agregado['TotalDespesas'].max(),
            'desvio_total_despesas': self.df_agregado['TotalDespesas'].std(),
            'grupos_alta_variabilidade': self.df_agregado['AltaVariabilidade'].sum(),
            'ufs_unicas': self.df_agregado['UF'].nunique()
        }
        
        # Top 10 operadoras
        estatisticas['top_10'] = self.df_agregado.head(10)[
            ['Ranking', 'RazaoSocial', 'UF', 'TotalDespesas']
        ].to_dict('records')
        
        # Top 5 UFs
        top_ufs = self.df_agregado.groupby('UF')['TotalDespesas'].sum().sort_values(ascending=False).head(5)
        estatisticas['top_5_ufs'] = top_ufs.to_dict()
        
        # Distribui√ß√£o de variabilidade
        estatisticas['distribuicao_variabilidade'] = {
            'baixa': (self.df_agregado['CoeficienteVariacao'] < 25).sum(),
            'media': ((self.df_agregado['CoeficienteVariacao'] >= 25) & 
                      (self.df_agregado['CoeficienteVariacao'] <= 50)).sum(),
            'alta': (self.df_agregado['CoeficienteVariacao'] > 50).sum()
        }
        
        print(f"  ‚úì An√°lise estat√≠stica conclu√≠da")
        logger.info("An√°lise estat√≠stica gerada")
        
        return estatisticas
    
    def exibir_estatisticas(self, estatisticas: dict) -> None:
        """
        Exibe estat√≠sticas no console.
        
        Args:
            estatisticas: Dicion√°rio com estat√≠sticas
        """
        print(f"\n" + "="*70)
        print("ESTAT√çSTICAS DOS DADOS AGREGADOS")
        print("="*70)
        
        print(f"\nüìä M√©tricas Gerais:")
        print(f"  Total de grupos (Operadora/UF): {estatisticas['total_grupos']:,}")
        print(f"  UFs √∫nicas: {estatisticas['ufs_unicas']}")
        print(f"  Soma total de despesas: R$ {estatisticas['soma_total_despesas']:,.2f}")
        
        print(f"\nüí∞ Estat√≠sticas de Despesas:")
        print(f"  M√©dia: R$ {estatisticas['media_total_despesas']:,.2f}")
        print(f"  Mediana: R$ {estatisticas['mediana_total_despesas']:,.2f}")
        print(f"  M√≠nimo: R$ {estatisticas['min_total_despesas']:,.2f}")
        print(f"  M√°ximo: R$ {estatisticas['max_total_despesas']:,.2f}")
        print(f"  Desvio Padr√£o: R$ {estatisticas['desvio_total_despesas']:,.2f}")
        
        print(f"\nüèÜ Top 10 Operadoras (Maior Total de Despesas):")
        for item in estatisticas['top_10']:
            print(f"  {item['Ranking']}¬∫. {item['RazaoSocial'][:40]:<40} ({item['UF']}) - R$ {item['TotalDespesas']:,.2f}")
        
        print(f"\nüó∫Ô∏è  Top 5 UFs (Maior Total de Despesas):")
        for i, (uf, total) in enumerate(estatisticas['top_5_ufs'].items(), 1):
            print(f"  {i}¬∫. {uf} - R$ {total:,.2f}")
        
        print(f"\nüìâ Variabilidade de Despesas:")
        print(f"  Baixa variabilidade (CV < 25%): {estatisticas['distribuicao_variabilidade']['baixa']:,}")
        print(f"  M√©dia variabilidade (25% ‚â§ CV ‚â§ 50%): {estatisticas['distribuicao_variabilidade']['media']:,}")
        print(f"  Alta variabilidade (CV > 50%): {estatisticas['distribuicao_variabilidade']['alta']:,}")
    
    def gerar_relatorio(self, arquivo_saida: Path, estatisticas: dict) -> None:
        """
        Gera relat√≥rio detalhado em arquivo texto.
        
        Args:
            arquivo_saida: Path do arquivo de relat√≥rio
            estatisticas: Dicion√°rio com estat√≠sticas
        """
        print(f"\nüìÑ Gerando relat√≥rio...")
        
        with open(arquivo_saida, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("RELAT√ìRIO DE AGREGA√á√ÉO E ESTAT√çSTICAS - ETAPA 2.3\n")
            f.write("="*70 + "\n\n")
            f.write(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n")
            
            f.write("ESTAT√çSTICAS GERAIS:\n")
            f.write("-" * 70 + "\n")
            f.write(f"Total de grupos (Operadora/UF): {estatisticas['total_grupos']:,}\n")
            f.write(f"UFs √∫nicas: {estatisticas['ufs_unicas']}\n")
            f.write(f"Soma total de despesas: R$ {estatisticas['soma_total_despesas']:,.2f}\n\n")
            
            f.write("M√âTRICAS DE DESPESAS:\n")
            f.write("-" * 70 + "\n")
            f.write(f"M√©dia: R$ {estatisticas['media_total_despesas']:,.2f}\n")
            f.write(f"Mediana: R$ {estatisticas['mediana_total_despesas']:,.2f}\n")
            f.write(f"M√≠nimo: R$ {estatisticas['min_total_despesas']:,.2f}\n")
            f.write(f"M√°ximo: R$ {estatisticas['max_total_despesas']:,.2f}\n")
            f.write(f"Desvio Padr√£o: R$ {estatisticas['desvio_total_despesas']:,.2f}\n\n")
            
            f.write("TOP 10 OPERADORAS:\n")
            f.write("-" * 70 + "\n")
            for item in estatisticas['top_10']:
                f.write(f"{item['Ranking']}¬∫. {item['RazaoSocial']} ({item['UF']}) - R$ {item['TotalDespesas']:,.2f}\n")
            f.write("\n")
            
            f.write("TOP 5 UFS:\n")
            f.write("-" * 70 + "\n")
            for i, (uf, total) in enumerate(estatisticas['top_5_ufs'].items(), 1):
                f.write(f"{i}¬∫. {uf} - R$ {total:,.2f}\n")
            f.write("\n")
            
            f.write("="*70 + "\n")
        
        print(f"  ‚úì Relat√≥rio salvo em: {arquivo_saida}")
        logger.info(f"Relat√≥rio gerado: {arquivo_saida}")
    
    def salvar_dados_agregados(self, arquivo_saida: Path) -> None:
        """
        Salva dados agregados em CSV.
        
        Args:
            arquivo_saida: Path do arquivo de sa√≠da
        """
        print(f"\nüíæ Salvando dados agregados...")
        
        self.df_agregado.to_csv(
            arquivo_saida,
            index=False,
            encoding='utf-8',
            sep=';',
            float_format='%.2f'  # 2 casas decimais
        )
        
        tamanho = arquivo_saida.stat().st_size
        print(f"  ‚úì Arquivo salvo: {arquivo_saida.name} ({bytes_para_humano(tamanho)})")
        logger.info(f"Dados agregados salvos: {arquivo_saida}")
    
    def compactar_arquivo_final(self, arquivo_csv: Path, arquivo_zip: Path) -> None:
        """
        Compacta CSV final em ZIP.
        
        Args:
            arquivo_csv: Path do CSV para compactar
            arquivo_zip: Path do ZIP de sa√≠da
        """
        print(f"\nüóúÔ∏è  Compactando arquivo final...")
        
        with zipfile.ZipFile(arquivo_zip, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.write(arquivo_csv, arquivo_csv.name)
        
        tamanho_csv = arquivo_csv.stat().st_size
        tamanho_zip = arquivo_zip.stat().st_size
        compressao = (1 - tamanho_zip / tamanho_csv) * 100
        
        print(f"  ‚úì ZIP gerado: {arquivo_zip.name}")
        print(f"  ‚úì Tamanho original: {bytes_para_humano(tamanho_csv)}")
        print(f"  ‚úì Tamanho compactado: {bytes_para_humano(tamanho_zip)}")
        print(f"  ‚úì Compress√£o: {compressao:.1f}%")
        
        logger.info(f"Arquivo compactado: {arquivo_zip}")


def main():
    """Fun√ß√£o principal."""
    print("="*70)
    print("ETAPA 2.3: AGREGA√á√ÉO E ESTAT√çSTICAS")
    print("="*70)
    
    try:
        # Caminhos
        saida_dir = PROJETO_RAIZ / "output"
        arquivo_entrada = saida_dir / "dados_enriquecidos.csv"
        arquivo_saida_csv = saida_dir / "despesas_agregadas.csv"
        arquivo_saida_zip = saida_dir / "Teste_Douglas_Ribeiro.zip"
        arquivo_relatorio = saida_dir / "relatorio_agregacao.txt"
        
        # Criar diret√≥rio de sa√≠da
        arquivo_saida_csv.parent.mkdir(parents=True, exist_ok=True)
        
        # Criar agregador
        agregador = AgregadorDados(arquivo_entrada)
        
        # Executar agrega√ß√£o
        agregador.carregar_dados()
        agregador.preparar_dados()
        agregador.agregar_dados()
        agregador.ordenar_dados()
        
        # An√°lise estat√≠stica
        estatisticas = agregador.gerar_analise_estatistica()
        agregador.exibir_estatisticas(estatisticas)
        
        # Gerar relat√≥rio
        agregador.gerar_relatorio(arquivo_relatorio, estatisticas)
        
        # Salvar dados
        agregador.salvar_dados_agregados(arquivo_saida_csv)
        
        # Compactar arquivo final
        agregador.compactar_arquivo_final(arquivo_saida_csv, arquivo_saida_zip)
        
        print("\n" + "="*70)
        print("‚úÖ ETAPA 2.3 CONCLU√çDA COM SUCESSO!")
        print("="*70)
        print(f"üìÅ Arquivo final: {arquivo_saida_zip}")
        print("="*70 + "\n")
        
        return 0
    
    except Exception as e:
        print(f"\n‚ùå ERRO: {e}\n")
        logger.error(f"Erro na agrega√ß√£o: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())